{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch data from Binance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    binance = ccxt.binance()\n",
    "    \n",
    "    # End time is current date\n",
    "    end_time = datetime.datetime.now()\n",
    "    \n",
    "    # Start time is 2 years from current date\n",
    "    start_time = end_time - datetime.timedelta(days=730)\n",
    "    \n",
    "    # Lists to store fetched data\n",
    "    ohlcv_list = []\n",
    "    \n",
    "    # Loop to fetch data monthly\n",
    "    while start_time < end_time:\n",
    "        since_time = start_time.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'\n",
    "        ohlc = binance.fetch_ohlcv('BTC/USDT', '1h', since=binance.parse8601(since_time))\n",
    "        \n",
    "        # If no data is returned, break\n",
    "        if not ohlc:\n",
    "            break\n",
    "        \n",
    "        ohlcv_list.extend(ohlc)\n",
    "        \n",
    "        # Add one month to start time for next iteration\n",
    "        start_time += datetime.timedelta(days=30)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(ohlcv_list, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Remove duplicates, if any, and sort by timestamp\n",
    "    df = df[~df.index.duplicated(keep='first')].sort_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = fetch_data()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Technical Indicators using Ta-Lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    close = df['close'].values\n",
    "    high = df['high'].values\n",
    "    low = df['low'].values\n",
    "    volume = df['volume'].values\n",
    "    \n",
    "    # RSI\n",
    "    df['rsi'] = talib.RSI(close)\n",
    "\n",
    "    # MA5 and MA10\n",
    "    df['ma5'] = talib.SMA(close, timeperiod=5)\n",
    "    df['ma10'] = talib.SMA(close, timeperiod=10)\n",
    "    \n",
    "    # OBV\n",
    "    df['obv'] = talib.OBV(close, volume)\n",
    "    \n",
    "    # MACD\n",
    "    macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df['macd'] = macd\n",
    "    df['macdsignal'] = macdsignal\n",
    "    df['macdhist'] = macdhist\n",
    "    \n",
    "    # ATR\n",
    "    df['atr'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    slowk, slowd = talib.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "    df['slowk'] = slowk\n",
    "    df['slowd'] = slowd\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    upper, middle, lower = talib.BBANDS(close, timeperiod=20)\n",
    "    df['bb_upper'] = upper\n",
    "    df['bb_middle'] = middle\n",
    "    df['bb_lower'] = lower\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = add_technical_indicators(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NaN values after adding technical indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values\n",
    "df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of technical indicators\n",
    "indicators = [col for col in df.columns if col not in ['open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "# Feature Correlation Analysis\n",
    "correlation_matrix = df[['close'] + indicators].corr()\n",
    "\n",
    "# Feature Correlation Analysis\n",
    "correlation_matrix = df[['close'] + indicators].corr()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your dataframe\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Choose a specific feature\n",
    "feature = 'close'\n",
    "\n",
    "# Extract correlations for that feature\n",
    "correlations = correlation_matrix[feature]\n",
    "\n",
    "# Print the columns and their correlation values with 'close'\n",
    "for col, val in correlations.items():\n",
    "    print(f\"{col} - {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data for Prophet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prophet_data(df):\n",
    "    # Convert the dataframe suitable for Prophet\n",
    "    df_prophet = df.reset_index().rename(columns={\"timestamp\": \"ds\", \"close\": \"y\"})\n",
    "    \n",
    "    # Remove the standard columns to get only the technical indicators\n",
    "    indicators = [col for col in df_prophet.columns if col not in ['ds', 'y', 'open', 'high', 'low', 'volume']]\n",
    "    \n",
    "    return df_prophet, indicators\n",
    "\n",
    "df_prophet = prepare_prophet_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning for Prophet model using Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_prophet_parameters(df_prophet, indicators):\n",
    "    # Splitting data into training and validation sets\n",
    "    train_size = int(0.9 * len(df_prophet))\n",
    "    train_data = df_prophet.iloc[:train_size]\n",
    "    validation_data = df_prophet.iloc[train_size:]\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "        'changepoint_prior_scale': [0.01, 0.05, 0.1, 0.5],\n",
    "        'yearly_seasonality': [True, False],\n",
    "        'weekly_seasonality': [True, False],\n",
    "        'daily_seasonality': [True, False]\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "    # Placeholder for best params and RMSE\n",
    "    best_params = {}\n",
    "    lowest_rmse = float('inf')\n",
    "    \n",
    "    # Function to train and evaluate a model\n",
    "    def train_evaluate_model(params, train, validation, indicators):\n",
    "        model = Prophet(**params)\n",
    "        for indicator in indicators:\n",
    "            model.add_regressor(indicator)\n",
    "        model.fit(train)\n",
    "        future = model.make_future_dataframe(periods=len(validation))\n",
    "        for indicator in indicators:\n",
    "            future[indicator] = pd.concat([train[indicator], validation[indicator]], ignore_index=True)\n",
    "        forecast = model.predict(future)\n",
    "        rmse = np.sqrt(mean_squared_error(validation['y'], forecast[-len(validation):]['yhat']))\n",
    "        return rmse\n",
    "\n",
    "    # Grid search loop\n",
    "    for params in all_params:\n",
    "        rmse = train_evaluate_model(params, train_data, validation_data, indicators)\n",
    "        if rmse < lowest_rmse:\n",
    "            best_params = params\n",
    "            lowest_rmse = rmse\n",
    "\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecast using Prophet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(df, hours=24):\n",
    "    df_prophet, indicators = prepare_prophet_data(df)\n",
    "    \n",
    "    # Get the best parameters\n",
    "    best_params = tune_prophet_parameters(df_prophet, indicators)\n",
    "    \n",
    "    model = Prophet(**best_params)\n",
    "    \n",
    "    # Dynamically add regressors based on the indicators list\n",
    "    for indicator in indicators:\n",
    "        model.add_regressor(indicator)\n",
    "    \n",
    "    model.fit(df_prophet)\n",
    "\n",
    "    future = model.make_future_dataframe(periods=hours, freq='H')\n",
    "    \n",
    "    # IMPORTANT: Dynamically add regressors to future dataframe\n",
    "    for indicator in indicators:\n",
    "        future[indicator] = pd.concat([df_prophet[indicator], pd.Series([np.nan] * hours)], ignore_index=True).ffill()\n",
    "\n",
    "    forecast = model.predict(future)\n",
    "    return forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(hours)\n",
    "\n",
    "forecast_data = forecast(df, hours=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(forecast_data):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add actual data\n",
    "    fig.add_trace(go.Scatter(x=forecast_data['ds'], y=forecast_data['yhat'], mode='lines', name='Predicted'))\n",
    "    \n",
    "    # Add confidence intervals\n",
    "    fig.add_trace(go.Scatter(x=forecast_data['ds'], y=forecast_data['yhat_upper'], fill='tonexty', mode='none', name='Upper Bound'))\n",
    "    fig.add_trace(go.Scatter(x=forecast_data['ds'], y=forecast_data['yhat_lower'], fill='tonexty', mode='none', name='Lower Bound'))\n",
    "    \n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_forecast(forecast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual price vs. the predicted price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(df_actual, df_forecast):\n",
    "    \"\"\"\n",
    "    Plot actual vs. predicted prices.\n",
    "    \n",
    "    Args:\n",
    "    - df_actual: DataFrame containing the actual prices with a 'timestamp' index and a 'close' column.\n",
    "    - df_forecast: DataFrame containing the predicted prices with a 'timestamp' index and a 'yhat' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a trace for actual prices\n",
    "    trace_actual = go.Scatter(\n",
    "        x=df_actual.index,\n",
    "        y=df_actual['close'],\n",
    "        mode='lines',\n",
    "        name='Actual Price'\n",
    "    )\n",
    "    \n",
    "    # Create a trace for predicted prices\n",
    "    trace_predicted = go.Scatter(\n",
    "        x=df_forecast['ds'],\n",
    "        y=df_forecast['yhat'],\n",
    "        mode='lines',\n",
    "        name='Predicted Price'\n",
    "    )\n",
    "    \n",
    "    # Create the layout\n",
    "    layout = go.Layout(\n",
    "        title='Actual vs. Predicted Prices',\n",
    "        xaxis=dict(title='Date'),\n",
    "        yaxis=dict(title='Price'),\n",
    "        template='plotly_dark'  # Using the dark mode\n",
    "    )\n",
    "    \n",
    "    # Create the figure and add the traces\n",
    "    fig = go.Figure(data=[trace_actual, trace_predicted], layout=layout)\n",
    "    \n",
    "    # Display the figure\n",
    "    fig.show()\n",
    "    \n",
    "plot_actual_vs_predicted(df, forecast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual price vs. the predicted price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_actual_with_predicted(df_actual, df_forecast):\n",
    "    \"\"\"\n",
    "    Merge current and predicted prices into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df_actual: DataFrame containing the actual prices with a 'timestamp' index and a 'close' column.\n",
    "    - df_forecast: DataFrame containing the predicted prices with a 'ds' column and a 'yhat' column.\n",
    "\n",
    "    Returns:\n",
    "    - merged_df: DataFrame containing columns 'timestamp', 'current_price', and 'predicted_price'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the most recent (i.e., current) price\n",
    "    current_price = df_actual['close'].iloc[-1]\n",
    "    \n",
    "    # Create a DataFrame with timestamps from df_forecast and filled with the current price\n",
    "    df_current_price = pd.DataFrame({\n",
    "        'ds': df_forecast['ds'],\n",
    "        'current_price': current_price\n",
    "    })\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    merged_df = pd.merge(df_current_price, df_forecast[['ds', 'yhat']], on='ds', how='right')\n",
    "    merged_df.rename(columns={'yhat': 'predicted_price'}, inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Create the merged DataFrame\n",
    "merged_data = merge_actual_with_predicted(df, forecast_data)\n",
    "\n",
    "# Display the merged data\n",
    "print(merged_data[['ds', 'current_price', 'predicted_price']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

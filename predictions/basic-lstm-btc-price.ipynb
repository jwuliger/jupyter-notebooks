{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(symbol='BTC/USDT', time_frame='1h', from_ts_str='2021-01-01T00:00:00Z'):\n",
    "    \n",
    "    # Initialize the Binance exchange API\n",
    "    binance = ccxt.binance()\n",
    "\n",
    "    since = binance.parse8601(from_ts_str)\n",
    "\n",
    "    # Fetch new data from the exchange\n",
    "    new_ohlcv = binance.fetch_ohlcv(symbol, time_frame, since=since, limit=1000)\n",
    "    \n",
    "    # Initialize the DataFrame with the first batch of data\n",
    "    columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df = pd.DataFrame(new_ohlcv, columns=columns)\n",
    "\n",
    "    batch_number = 1\n",
    "    while len(new_ohlcv) == 1000:\n",
    "        print(f\"Fetching batch {batch_number}...\")\n",
    "        from_ts = new_ohlcv[-1][0] + 1  # add 1 millisecond to avoid duplicates\n",
    "        new_ohlcv = binance.fetch_ohlcv(symbol, time_frame, since=from_ts, limit=1000)\n",
    "        \n",
    "        # Append new data to the DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame(new_ohlcv, columns=columns)], ignore_index=True)\n",
    "\n",
    "        batch_number += 1\n",
    "\n",
    "    print(\"Data fetching completed!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \n",
    "    # Computing RSI values\n",
    "    df['rsi'] = talib.RSI(df['close'].values, timeperiod=16)\n",
    "    \n",
    "    # Computing ATR values\n",
    "    df['atr'] = talib.ATR(df['high'].values, df['low'].values, df['close'].values, timeperiod=14)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Scaling Close price values\n",
    "    scaler_price = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_close'] = scaler_price.fit_transform(df['close'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Scaling RSI values\n",
    "    scaler_rsi = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_rsi'] = scaler_rsi.fit_transform(df['rsi'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Scaling ATR values\n",
    "    scaler_atr = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_atr'] = scaler_atr.fit_transform(df['atr'].values.reshape(-1, 1))\n",
    "    \n",
    "    return df, scaler_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the LSTM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_dataset(df):\n",
    "    X, y = [], []\n",
    "    for i in range(60, len(df)):\n",
    "        X.append(np.column_stack(\n",
    "            (df.scaled_close.values[i-60:i], df.scaled_rsi.values[i-60:i])))\n",
    "        y.append(df.scaled_close.values[i])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=(60, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching batch 1...\n",
      "Fetching batch 2...\n",
      "Fetching batch 3...\n",
      "Fetching batch 4...\n",
      "Fetching batch 5...\n",
      "Fetching batch 6...\n",
      "Fetching batch 7...\n",
      "Fetching batch 8...\n",
      "Fetching batch 9...\n",
      "Fetching batch 10...\n",
      "Fetching batch 11...\n",
      "Fetching batch 12...\n",
      "Fetching batch 13...\n",
      "Fetching batch 14...\n",
      "Fetching batch 15...\n",
      "Fetching batch 16...\n",
      "Fetching batch 17...\n",
      "Fetching batch 18...\n",
      "Fetching batch 19...\n",
      "Fetching batch 20...\n",
      "Fetching batch 21...\n",
      "Fetching batch 22...\n",
      "Fetching batch 23...\n",
      "Fetching batch 24...\n",
      "Data fetching completed!\n",
      "Epoch 1/10\n",
      "381/381 [==============================] - 41s 100ms/step - loss: 0.0026\n",
      "Epoch 2/10\n",
      "381/381 [==============================] - 40s 106ms/step - loss: 7.7759e-04\n",
      "Epoch 3/10\n",
      "381/381 [==============================] - 41s 107ms/step - loss: 6.7833e-04\n",
      "Epoch 4/10\n",
      "381/381 [==============================] - 42s 110ms/step - loss: 6.1431e-04\n",
      "Epoch 5/10\n",
      "381/381 [==============================] - 41s 108ms/step - loss: 5.6781e-04\n",
      "Epoch 6/10\n",
      "381/381 [==============================] - 41s 107ms/step - loss: 4.6142e-04\n",
      "Epoch 7/10\n",
      "381/381 [==============================] - 41s 108ms/step - loss: 4.4757e-04\n",
      "Epoch 8/10\n",
      "381/381 [==============================] - 42s 111ms/step - loss: 4.0078e-04\n",
      "Epoch 9/10\n",
      "381/381 [==============================] - 41s 107ms/step - loss: 3.6889e-04\n",
      "Epoch 10/10\n",
      "381/381 [==============================] - 38s 100ms/step - loss: 3.3152e-04\n",
      "762/762 [==============================] - 14s 18ms/step\n",
      "Predicted BTC Price for the last hour in dataset: $28722.642578125\n"
     ]
    }
   ],
   "source": [
    "df = fetch_data()\n",
    "df, scaler_price = preprocess_data(df)\n",
    "X, y = create_dataset(df)\n",
    "\n",
    "model = create_model()\n",
    "    \n",
    "model.fit(X, y, epochs=10, batch_size=64)\n",
    "\n",
    "# Using the entire X array to make the prediction\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# I might want to do something more meaningful with the predictions. \n",
    "# For simplicity, I'm just printing the last prediction.\n",
    "predicted_price = scaler_price.inverse_transform(predictions[-1].reshape(-1, 1))\n",
    "print(f\"Predicted BTC Price for the last hour in dataset: ${predicted_price[0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_data(symbol='BTC/USDT', time_frame='1h', from_ts_str='2021-01-01 00:00:00'):\n",
    "    # Initialize the Binance exchange API\n",
    "    binance = ccxt.binance()\n",
    "\n",
    "    from_ts = int(datetime.timestamp(datetime.strptime(from_ts_str, '%Y-%m-%d %H:%M:%S')) * 1000)\n",
    "\n",
    "    # Fetch new data from the exchange\n",
    "    new_ohlcv = binance.fetch_ohlcv(symbol, time_frame, since=from_ts, limit=1000)\n",
    "    \n",
    "    # Initialize the DataFrame with the first batch of data\n",
    "    columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df = pd.DataFrame(new_ohlcv, columns=columns)\n",
    "\n",
    "    batch_number = 1\n",
    "    while len(new_ohlcv) == 1000:\n",
    "        print(f\"Fetching batch {batch_number}...\")\n",
    "        from_ts = new_ohlcv[-1][0] + 1  # add 1 millisecond to avoid duplicates\n",
    "        new_ohlcv = binance.fetch_ohlcv(symbol, time_frame, since=from_ts, limit=1000)\n",
    "        \n",
    "        # Append new data to the DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame(new_ohlcv, columns=columns)], ignore_index=True)\n",
    "\n",
    "        batch_number += 1\n",
    "\n",
    "    print(\"Data fetching completed!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df['rsi'] = talib.RSI(df['close'].values, timeperiod=14)\n",
    "    df.dropna(inplace=True)\n",
    "    scaler_price = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_close'] = scaler_price.fit_transform(\n",
    "        df['close'].values.reshape(-1, 1))\n",
    "    scaler_rsi = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_rsi'] = scaler_rsi.fit_transform(\n",
    "        df['rsi'].values.reshape(-1, 1))\n",
    "    return df, scaler_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the LSTM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_dataset(df):\n",
    "    X, y = [], []\n",
    "    for i in range(60, len(df)):\n",
    "        X.append(np.column_stack(\n",
    "            (df.scaled_close.values[i-60:i], df.scaled_rsi.values[i-60:i])))\n",
    "        y.append(df.scaled_close.values[i])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=(60, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "df = fetch_data()\n",
    "df, scaler_price = preprocess_data(df)\n",
    "X, y = create_dataset(df)\n",
    "\n",
    "model_path = \"bitcoin_prediction_model.keras\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    model = create_model()\n",
    "    print(\"Created a new model.\")\n",
    "model.fit(X, y, epochs=10, batch_size=64)\n",
    "\n",
    "model.save(model_path)\n",
    "print(f\"Model updated and saved to {model_path}\")\n",
    "\n",
    "last_60 = df[-60:]\n",
    "next_input = np.column_stack((last_60.scaled_close.values, last_60.scaled_rsi.values))\n",
    "next_input = np.reshape(next_input, (1, 60, 2))\n",
    "prediction = model.predict(next_input)\n",
    "\n",
    "predicted_price = scaler_price.inverse_transform(prediction)\n",
    "print(f\"Predicted BTC Price for next 1h: ${predicted_price[0][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
